defaults:
  - _self_
  - rewards:
    - action_penalty
    - object_pos_err

name: warp_claw_old

config:
  _target_: dmanip.envs.ClawWarpEnvOld
  num_envs: 64
  episode_length: 500
  render: ${general.render}
  no_grad: ???
  # rew_params: 
  #   action_penalty: ${...rewards.action_penalty}
  #   object_pos_err: ${...rewards.object_pos_err}
  #   object_joint_pos_err: ${...rewards.object_joint_pos_err}
  stochastic_init: true
  seed: ${general.seed}
  action_type: ${action:torque}
  action_strength: 10.0
  object_type: ${object:octprism}
  goal_type: ${goal:orientation}
  reward_type: ${reward:delta}
  # debug: ${debug}

shac:
  steps_num: 16
  actor_lr: 2e-3
  critic_lr: 4e-3
  actor_mlp:
    units: [128, 64, 32]
  critic_mlp:
    units: [64, 64]

ahac:
  actor_lr: 2e-3
  critic_lr: 4e-3
  max_epochs: 500
  actor_mlp:
    units: [128, 64, 32]
  critic_mlp:
    units: [64, 64]
  save_interval: 100

ahac5:
  actor_lr: 2e-3
  critic_lr: 4e-3
  h_lr: 1e-2
  max_epochs: 500
  actor_mlp:
    units: [128, 64, 32]
  critic_mlp:
    units: [64, 64]
  save_interval: 100

ppo:
  max_epochs: 500
  minibatch_size: 512
  num_actors: 64
  horizon_length: 32
  save_interval: 100
  save_best_after: 100
  actor_mlp:
    units: [128, 64, 32]

player:
  deterministic: True
  games_num: 12
  num_actors: 4
  print_stats: True
