defaults:
  - _self_
  - rewards:
    - action_penalty
    - object_pos_err
    - reach_bonus
    - rot_reward_delta

name: warp_repose_task

score_keys:
  - object_rot_err
  - object_pose_err
  - reach_bonus
  - action_penalty
  - net_energy

config:
  _target_: warp.envs.ReposeTask
  num_envs: 64
  episode_length: 250
  render: ${general.render}
  reward_params: 
    action_penalty: ${env.rewards.action_penalty}
    object_pos_err: ${env.rewards.object_pos_err}
      # hand_joint_pos_err: ${task.rewards.hand_joint_pos_err}
    rot_reward_delta: ${env.rewards.rot_reward_delta}
    reach_bonus: ${env.rewards.reach_bonus}
  hand_type: ${hand:allegro}
  stochastic_init: true
  use_autograd: true
  use_graph_capture: true
  # use_graph_capture: ${eval:'("shac" not in "${alg.name}")'}
  # no_grad: ${eval:'("shac" not in "${alg.name}")'}


ppo:
  max_epochs: 5000
  save_best_after: 100
  save_frequency: 400
  num_actors: 2048
  minibatch_size: 16384
  steps_num: 32
  actor_mlp:
    units: [64, 64]

player:
  deterministic: true
  games_num: 100000
  print_stats: true
