name: shac2
params:
  network:
    actor: 
      _target_: shac.models.actor.ActorStochasticMLP # ActorDeterministicMLP
      device: 
      cfg_network:
        actor_mlp:
          units: ${resolve_default:${eval:"[64, 64]"},${env.shac2.actor_mlp.units}}
          activation: elu

    critic:
      _target_: shac.models.critic.CriticMLP
      cfg_network:
        critic_mlp:
          units: ${resolve_default:${eval:"[64, 64]"},${env.shac2.critic_mlp.units}}
          activation: elu

  config:
    name: ${env.name}_${...name}
    actor_optimizer: ${..default_actor_opt}
    critic_optimizer: ${..default_critic_opt}
    lr_schedule: linear # ['constant', 'linear']
    target_critic_alpha: ${resolve_default:0.2,${env.shac2.target_critic_alpha}}
    obs_rms: True
    ret_rms: False
    critic_iterations: 16
    critic_method: td-lambda # ['td-lambda', 'one-step']
    lam: 0.95
    num_batch: 4
    gamma: 0.99
    max_epochs: ${resolve_default:2000,${env.shac2.max_epochs}}
    steps_num: ${resolve_default:32,${env.shac2.steps_num}}
    grad_norm: 1.0
    truncate_grads: True
    save_interval: ${resolve_default:400,${env.shac2.save_interval}}
    mixed_precision: False
    multi_gpu: ${general.multi_gpu}
    early_stopping_patience: ${.max_epochs}
    rew_scale: 1

    player:
      determenistic: True
      games_num: ${resolve_default:1,${env.player.games_num}}
      num_actors: ${resolve_default:1,${env.player.num_actors}}
      print_stats: True

  default_actor_opt:
    _target_: torch.optim.Adam
    lr: ${resolve_default:2e-3,${env.shac2.actor_lr}} # adam
    betas: ${resolve_default:${eval:"[0.7, 0.95]"},${env.shac2.betas}} # adam

  default_critic_opt:
    _target_: torch.optim.Adam
    lr: ${resolve_default:2e-3,${env.shac2.critic_lr}} # adam
    betas: ${resolve_default:${eval:"[0.7, 0.95]"},${env.shac2.betas}} # adam

  default_adaptive_scheduler:
    _target_: rl_games.common.schedulers.AdaptiveScheduler
    kl_threshold: 0.008

  default_linear_scheduler:
    _target_: rl_games.common.schedulers.LinearScheduler
    start_lr: ${..default_actor_opt.lr}
    min_lr: 1e-5
    max_steps: ${..config.max_epochs}
    apply_to_entropy: False
